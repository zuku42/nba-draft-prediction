{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d08c6e",
   "metadata": {},
   "source": [
    "To tackle the task, it was first necessary to collect all the data that may be relevant to the problem (while at the same time being relatively easily available). It was clear from the start that it would not be enough to only look at one season’s data, as the sample constructed this way would be too small to build effective predictive models on. At the same time, looking back too far into the past could introduce a significant bias, as the basketball changed over the years and so did the most important factors that influenced players’ desirability in the draft (e.g. three-point shooting is a fundamental skill in a basketball player’s toolkit nowadays, whereas 20 years ago it was not nearly as important). When collecting data, it was necessary to find the right balance between the sample size, and its “expiration date”.\n",
    "\n",
    "As it turned out, a somewhat reasonable solution to this problem was forced upon the author of this project by the data availability itself. Because college basketball page of the Sports Reference portal provides an exhaustive dataset of all the players that played in the NCAA Division I reaching back many decades into the past, it was selected as the sole data source for this project. However, advanced performance measures (such as rebound percentage or win shares per 40 minutes) were not collected before the 2010/11 season. Therefore, as of January 2021, there were 10 full seasons of complete data available to be fetched, and it was decided to download data from all these years.\n",
    "\n",
    "The Sports Reference page was not equipped with an API that would facilitate the data collection, so a web crawler had to be developed to serve that function. It was built using Python and its two third-party libraries for HTML and website interaction automation: requests and selenium. A headless browser (Chromium) was used to fetch content that is generated upon loading the website. The data was downloaded in batches of 50 players at the time and saved in csv files to be later merged together. The progress (i.e. players and schools whose data was already downloaded) was kept tracked of using the checked_players.txt and checked_schools.txt text files.\n",
    "\n",
    "The whole process was achieved with the folllowing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5a8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9827450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_browser():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4032bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(url, js=False, driver=None):\n",
    "    if js:\n",
    "        driver.get(url)\n",
    "        contents = driver.page_source\n",
    "    else:\n",
    "        r = requests.get(url)\n",
    "        contents = r.content\n",
    "    return BeautifulSoup(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a185d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_name(name):\n",
    "    if 'NCAA' in name:\n",
    "        return name[:-4].strip()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b54c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rows(soup, _id):\n",
    "    table = soup.find('table', {'id': _id}).find('tbody')\n",
    "    rows = table.find_all('tr', {'class': None})\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78ed0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school_year(years_played):\n",
    "    if years_played >= 4:\n",
    "        return 'senior'\n",
    "    elif years_played == 3:\n",
    "        return 'junior'\n",
    "    elif years_played == 2:\n",
    "        return 'sophomore'\n",
    "    return 'freshman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a6dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dictionary(_dict):\n",
    "    return {key: [] for key in _dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15eca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_checked(text_file):\n",
    "    with open(text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f7d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checked(item_list, text_file):\n",
    "    with open(text_file, 'w') as file:\n",
    "        for item in item_list:\n",
    "            file.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81993d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_checkpoint(players_stats_dict, checked_players, checked_schools, filename='final_batch'):\n",
    "    temp_df = pd.DataFrame(player_stats_dict)\n",
    "    temp_df.to_csv(f'raw data/players data/{filename}.csv')\n",
    "    save_checked(checked_players, text_file='web scraper files/checked_players.txt')\n",
    "    save_checked(checked_schools, text_file='web scraper files/checked_schools.txt')\n",
    "    return clear_dictionary(player_stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b63a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 2011\n",
    "END = 2021\n",
    "BASE_URL = 'https://www.sports-reference.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "735aeb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_stats_dict = {'season': [], 'school_url': [], 'school_name': [], 'games_played': [],\n",
    "                     'win_pct': [], 'ncaa_tournament': [], 'pace': [], 'eff_fg_pct': []}\n",
    "\n",
    "for season in (range(START, END+1)):\n",
    "    school_stats_url = f'cbb/seasons/{season}-school-stats.html'\n",
    "    advanced_school_stats_url = f'cbb/seasons/{season}-advanced-school-stats.html'\n",
    "\n",
    "    basic_school_stats_soup = get_contents(BASE_URL + school_stats_url)\n",
    "    advanced_school_stats_soup = get_contents(BASE_URL + advanced_school_stats_url)\n",
    "\n",
    "    basic_school_stats_rows = find_rows(basic_school_stats_soup, 'basic_school_stats')\n",
    "    advanced_school_stats_rows = find_rows(advanced_school_stats_soup, 'adv_school_stats')\n",
    "\n",
    "    for b_row, a_row in zip(basic_school_stats_rows, advanced_school_stats_rows):\n",
    "        school_url = BASE_URL + b_row.find('a')['href']\n",
    "\n",
    "        school_name = b_row.find('td', {'data-stat': 'school_name'}).text\n",
    "        games_played = b_row.find('td', {'data-stat': 'g'}).text\n",
    "        win_pct = b_row.find('td', {'data-stat': 'win_loss_pct'}).text or 0\n",
    "        ncaa_tournament = ('NCAA' in school_name)\n",
    "\n",
    "        pace = a_row.find('td', {'data-stat': 'pace'}).text or 0\n",
    "        eff_fg_pct = a_row.find('td', {'data-stat': 'efg_pct'}).text or 0\n",
    "\n",
    "        school_stats_dict['season'].append(season)\n",
    "        school_stats_dict['school_url'].append(school_url)\n",
    "        school_stats_dict['school_name'].append(strip_name(school_name))\n",
    "        school_stats_dict['games_played'].append(int(games_played))\n",
    "        school_stats_dict['win_pct'].append(float(win_pct))\n",
    "        school_stats_dict['ncaa_tournament'].append(int(ncaa_tournament))\n",
    "        school_stats_dict['pace'].append(float(pace))\n",
    "        school_stats_dict['eff_fg_pct'].append(float(eff_fg_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c40dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_ratings_dict = {'season': [], 'school_name': [], 'srs_off': [], 'srs_def': [], 'sos': [],\n",
    "                       'team_ppg': [], 'opp_ppg': [], 'off_rating': [], 'def_rating': []}\n",
    "\n",
    "for season in (range(START, END+1)):\n",
    "    school_ratings_url = f'cbb/seasons/{season}-ratings.html'\n",
    "    school_ratings_soup = get_contents(BASE_URL + school_ratings_url)\n",
    "    school_ratings_rows = find_rows(school_ratings_soup, 'ratings')\n",
    "\n",
    "    for row in school_ratings_rows:\n",
    "        school_name = row.find('td', {'data-stat': 'school_name'}).text\n",
    "        srs_off = row.find('td', {'data-stat': 'srs_off'}).text or 0\n",
    "        srs_def = row.find('td', {'data-stat': 'srs_def'}).text or 0\n",
    "        sos = row.find('td', {'data-stat': 'sos'}).text or 0\n",
    "        team_ppg = row.find('td', {'data-stat': 'pts_per_g'}).text or 0\n",
    "        opp_ppg = row.find('td', {'data-stat': 'opp_pts_per_g'}).text or 0\n",
    "        off_rating = row.find('td', {'data-stat': 'off_rtg'}).text or 0\n",
    "        def_rating = row.find('td', {'data-stat': 'def_rtg'}).text or 0\n",
    "\n",
    "        school_ratings_dict['season'].append(season)\n",
    "        school_ratings_dict['school_name'].append(school_name)\n",
    "        school_ratings_dict['srs_off'].append(float(srs_off))\n",
    "        school_ratings_dict['srs_def'].append(float(srs_def))\n",
    "        school_ratings_dict['sos'].append(float(sos))\n",
    "        school_ratings_dict['team_ppg'].append(team_ppg)\n",
    "        school_ratings_dict['opp_ppg'].append(opp_ppg)\n",
    "        school_ratings_dict['off_rating'].append(off_rating)\n",
    "        school_ratings_dict['def_rating'].append(def_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "509ca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_poll_dict = {'season': [], 'school_name': [], 'rank': []}\n",
    "\n",
    "for season in (range(START, END+1)):\n",
    "    school_poll_url = f'cbb/seasons/{season}-polls.html'\n",
    "    school_poll_soup = get_contents(BASE_URL + school_poll_url)\n",
    "    school_poll_rows = find_rows(school_poll_soup, 'ap-polls')\n",
    "\n",
    "    for row in school_poll_rows:\n",
    "        school_name = row.find('th', {'data-stat': 'school'}).text\n",
    "        rank = row.find_all('td')[-1].text\n",
    "\n",
    "        school_poll_dict['season'].append(season)\n",
    "        school_poll_dict['school_name'].append(school_name)\n",
    "        school_poll_dict['rank'].append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c0f424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_stats_df = pd.DataFrame(school_stats_dict)\n",
    "school_ratings_df = pd.DataFrame(school_ratings_dict)\n",
    "school_polls_df = pd.DataFrame(school_poll_dict)\n",
    "schools_df = pd.merge(school_stats_df, school_ratings_df, on=['season', 'school_name'])\n",
    "schools_df = pd.merge(schools_df, school_polls_df, on=['season', 'school_name'], how='left')\n",
    "schools_df.to_csv('raw_data/schools_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fccf263",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df = pd.read_csv('raw_data/schools_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facd45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_dict = {'name': [], 'season': [], 'school_url': [], 'position': [], 'height': [], 'weight': [], 'school_year': [],\n",
    "                     'games_played': [], 'games_started': [], 'games_won': [], 'mpg': [], 'fg_pct': [], 'fg3_pct': [],\n",
    "                     'fg3a': [],'ft_pct': [], 'fta': [], 'off_rpg': [], 'def_rpg': [], 'apg': [], 'spg': [], 'bpg': [],\n",
    "                     'tpg': [], 'fpg': [], 'ppg': [], 'per': [], 'ts_pct': [], 'eff_fg_pct': [], 'fg3a_rate': [],\n",
    "                     'off_reb_pct': [], 'def_reb_pct': [], 'ast_pct': [], 'usg_pct': [], 'win_shares_40_min': [],\n",
    "                     'plus_minus': [], 'max_points': [], 'max_assists': [], 'max_steals': [], 'max_blocks': [],\n",
    "                     'max_rebounds': [], 'std_points': [], 'std_assists': [], 'std_steals': [], 'std_blocks': [],\n",
    "                     'std_rebounds': [], 'draft': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2293b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = initialize_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f72d5e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checked_players = read_checked(text_file='web scraper files/checked_players.txt')\n",
    "checked_schools = read_checked(text_file='web scraper files/checked_schools.txt')\n",
    "\n",
    "n_files = len(list(glob.iglob('raw_data/players_data/*.csv')))\n",
    "n_iterations = 50\n",
    "\n",
    "for season, school_url in zip(schools_df['season'], schools_df['school_url']):\n",
    "    if school_url not in checked_schools:\n",
    "        school_page = get_contents(school_url)\n",
    "\n",
    "        try:\n",
    "            roster_table = school_page.find('table', {'id': 'roster'}).find('tbody')\n",
    "            players = roster_table.find_all('tr')\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        for player in players:\n",
    "            player_url = BASE_URL + player.find('a')['href']\n",
    "\n",
    "            if player_url not in checked_players:\n",
    "                name = player.find('a').text\n",
    "                position = player.find('td', {'data-stat': 'pos'}).text\n",
    "                height = player.find('td', {'data-stat': 'height'}).text\n",
    "                weight = player.find('td', {'data-stat': 'weight'}).text\n",
    "\n",
    "                player_page = get_contents(player_url, js=True, driver=driver)\n",
    "\n",
    "                per_game_rows = find_rows(player_page, 'players_per_game')\n",
    "\n",
    "                years_played = len(per_game_rows)\n",
    "\n",
    "                per_game_last_season = per_game_rows[-1]\n",
    "\n",
    "                season = '20' + per_game_last_season.find('th', {'data-stat': 'season'}).find('a').text[-2:]\n",
    "                try:\n",
    "                    season_school_url = BASE_URL + per_game_last_season.find('td', {'data-stat': 'school_name'}).find('a')['href']\n",
    "                except TypeError:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    games_played = per_game_last_season.find('td', {'data-stat': 'g'}).text\n",
    "                    games_started = per_game_last_season.find('td', {'data-stat': 'gs'}).text\n",
    "                    mpg = per_game_last_season.find('td', {'data-stat': 'mp_per_g'}).text\n",
    "                    fg_pct = per_game_last_season.find('td', {'data-stat': 'fg_pct'}).text\n",
    "                    fg3_pct = per_game_last_season.find('td', {'data-stat': 'fg3_pct'}).text\n",
    "                    fg3a = per_game_last_season.find('td', {'data-stat': 'fg3a_per_g'}).text\n",
    "                    ft_pct = per_game_last_season.find('td', {'data-stat': 'ft_pct'}).text\n",
    "                    fta = per_game_last_season.find('td', {'data-stat': 'fta_per_g'}).text\n",
    "                    off_rpg = per_game_last_season.find('td', {'data-stat': 'orb_per_g'}).text\n",
    "                    def_rpg = per_game_last_season.find('td', {'data-stat': 'drb_per_g'}).text\n",
    "                    apg = per_game_last_season.find('td', {'data-stat': 'ast_per_g'}).text\n",
    "                    spg = per_game_last_season.find('td', {'data-stat': 'stl_per_g'}).text\n",
    "                    bpg = per_game_last_season.find('td', {'data-stat': 'blk_per_g'}).text\n",
    "                    tpg = per_game_last_season.find('td', {'data-stat': 'tov_per_g'}).text\n",
    "                    fpg = per_game_last_season.find('td', {'data-stat': 'pf_per_g'}).text\n",
    "                    ppg = per_game_last_season.find('td', {'data-stat': 'pts_per_g'}).text\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                    \n",
    "                advanced_rows = find_rows(player_page, 'players_advanced')\n",
    "                advanced_last_season = advanced_rows[-1]\n",
    "\n",
    "                per = advanced_last_season.find('td', {'data-stat': 'per'}).text\n",
    "                ts_pct = advanced_last_season.find('td', {'data-stat': 'ts_pct'}).text\n",
    "                eff_fg_pct = advanced_last_season.find('td', {'data-stat': 'efg_pct'}).text\n",
    "                fg3a_rate = advanced_last_season.find('td', {'data-stat': 'fg3a_per_fga_pct'}).text\n",
    "                off_reb_pct = advanced_last_season.find('td', {'data-stat': 'orb_pct'}).text\n",
    "                def_reb_pct = advanced_last_season.find('td', {'data-stat': 'drb_pct'}).text\n",
    "                ast_pct = advanced_last_season.find('td', {'data-stat': 'ast_pct'}).text\n",
    "                usg_pct = advanced_last_season.find('td', {'data-stat': 'usg_pct'}).text\n",
    "                win_shares_40_min = advanced_last_season.find('td', {'data-stat': 'ws_per_40'}).text\n",
    "                plus_minus = advanced_last_season.find('td', {'data-stat': 'bpm'}).text\n",
    "                \n",
    "                try:\n",
    "                    all_links = player_page.find_all('a', href=True)\n",
    "                    for link in all_links:\n",
    "                        if link.text == 'Basketball-Reference.com':\n",
    "                            external_url = link['href']\n",
    "                            external_soup = get_contents(external_url)\n",
    "                            external_info = external_soup.find('div', {'id': 'info'}).find_all('p')\n",
    "                            for item in external_info:\n",
    "                                if 'NBA Draft' in item.text:\n",
    "                                    draft = int(item.text[-30:-28].strip())\n",
    "                                    break\n",
    "                            else:\n",
    "                                draft = 'undrafted (NBA)'\n",
    "                            break\n",
    "                    else:\n",
    "                        draft = 'undrafted'\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                gamelog_url = player_url[:-5] + f'/gamelog/{season}/'\n",
    "                gamelog_page = get_contents(gamelog_url, js=True, driver=driver)\n",
    "                \n",
    "                try:\n",
    "                    gamelog_table = gamelog_page.find('table', {'id': 'gamelog'}).find('tbody')\n",
    "                    games = gamelog_table.find_all('tr', {'class': None})\n",
    "                except AttributeError:\n",
    "                    continue \n",
    "                    \n",
    "                points = []\n",
    "                assists = []\n",
    "                rebounds = []\n",
    "                steals = []\n",
    "                blocks = []\n",
    "                games_won = 0 \n",
    "\n",
    "                for game in games:\n",
    "                    pts = game.find('td', {'data-stat': 'pts'}).text\n",
    "                    ast = game.find('td', {'data-stat': 'ast'}).text\n",
    "                    rebs = game.find('td', {'data-stat': 'trb'}).text\n",
    "                    stl = game.find('td', {'data-stat': 'stl'}).text\n",
    "                    blk = game.find('td', {'data-stat': 'blk'}).text\n",
    "                    win = game.find('td', {'data-stat': 'game_result'}).text == 'W'\n",
    "\n",
    "                    points.append(int(pts))\n",
    "                    assists.append(int(ast))\n",
    "                    rebounds.append(int(rebs))\n",
    "                    steals.append(int(stl))\n",
    "                    blocks.append(int(blk))\n",
    "                    games_won += int(win)\n",
    "\n",
    "                player_stats_dict['name'].append(name)\n",
    "                player_stats_dict['season'].append(int(season))\n",
    "                player_stats_dict['school_url'].append(season_school_url)\n",
    "                player_stats_dict['position'].append(position)\n",
    "                player_stats_dict['height'].append(height)\n",
    "                player_stats_dict['weight'].append(weight)\n",
    "                player_stats_dict['school_year'].append(get_school_year(years_played))\n",
    "                player_stats_dict['games_played'].append(games_played)\n",
    "                player_stats_dict['games_started'].append(games_started)\n",
    "                player_stats_dict['games_won'].append(games_won)\n",
    "                player_stats_dict['mpg'].append(mpg)\n",
    "                player_stats_dict['fg_pct'].append(fg_pct)\n",
    "                player_stats_dict['fg3_pct'].append(fg3_pct)\n",
    "                player_stats_dict['fg3a'].append(fg3a)\n",
    "                player_stats_dict['ft_pct'].append(ft_pct)\n",
    "                player_stats_dict['fta'].append(fta)\n",
    "                player_stats_dict['off_rpg'].append(off_rpg)\n",
    "                player_stats_dict['def_rpg'].append(def_rpg)\n",
    "                player_stats_dict['apg'].append(apg)\n",
    "                player_stats_dict['spg'].append(spg)\n",
    "                player_stats_dict['bpg'].append(bpg)\n",
    "                player_stats_dict['tpg'].append(tpg)\n",
    "                player_stats_dict['fpg'].append(fpg)\n",
    "                player_stats_dict['ppg'].append(ppg)\n",
    "                player_stats_dict['per'].append(per)\n",
    "                player_stats_dict['ts_pct'].append(ts_pct)\n",
    "                player_stats_dict['eff_fg_pct'].append(eff_fg_pct)\n",
    "                player_stats_dict['fg3a_rate'].append(fg3a_rate)\n",
    "                player_stats_dict['off_reb_pct'].append(off_reb_pct)\n",
    "                player_stats_dict['def_reb_pct'].append(def_reb_pct)\n",
    "                player_stats_dict['ast_pct'].append(ast_pct)\n",
    "                player_stats_dict['usg_pct'].append(usg_pct)\n",
    "                player_stats_dict['win_shares_40_min'].append(win_shares_40_min)\n",
    "                player_stats_dict['plus_minus'].append(plus_minus)\n",
    "                player_stats_dict['max_points'].append(max(points))\n",
    "                player_stats_dict['max_assists'].append(max(assists))\n",
    "                player_stats_dict['max_steals'].append(max(steals))\n",
    "                player_stats_dict['max_blocks'].append(max(blocks))\n",
    "                player_stats_dict['max_rebounds'].append(max(rebounds))\n",
    "                player_stats_dict['std_points'].append(np.std(points))\n",
    "                player_stats_dict['std_assists'].append(np.std(assists))\n",
    "                player_stats_dict['std_steals'].append(np.std(steals))\n",
    "                player_stats_dict['std_blocks'].append(np.std(blocks))\n",
    "                player_stats_dict['std_rebounds'].append(np.std(rebounds))\n",
    "                player_stats_dict['draft'].append(draft)\n",
    "                \n",
    "                checked_players.append(player_url)\n",
    "                if len(checked_players)%n_iterations == 0:\n",
    "                    filename = f'batch_{int(len(checked_players)/n_iterations)}.csv'\n",
    "                    player_stats_dict = make_checkpoint(player_stats_dict,\n",
    "                                                        checked_players,\n",
    "                                                        checked_schools,\n",
    "                                                        filename=filename)\n",
    "        \n",
    "        checked_schools.append(school_url)\n",
    "        \n",
    "player_stats_dict = make_checkpoint(player_stats_dict, checked_players, checked_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
